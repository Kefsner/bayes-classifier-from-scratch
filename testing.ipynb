{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6dfdd2-40b4-4ab4-a9c1-17ae71cc2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0379688-60de-4c52-95c7-9b44e877ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_SPAM_PROB_FILE = 'prob-spam.txt'\n",
    "TOKEN_HAM_PROB_FILE = 'prob-ham.txt'\n",
    "TOKEN_ALL_PROB_FILE = 'prob-all.txt'\n",
    "\n",
    "TEST_FEATURE_MATRIX = 'test-features.txt'\n",
    "TEST_TARGET_FILE = 'test-target.txt'\n",
    "\n",
    "PROB_SPAM = 0.3318170331058883\n",
    "\n",
    "VOCAB_SIZE = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b188d3-2e5c-46e7-8462-736e28dd28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "x_test = np.loadtxt(TEST_FEATURE_MATRIX, delimiter=' ')\n",
    "# Target\n",
    "y_test = np.loadtxt(TEST_TARGET_FILE, delimiter=' ')\n",
    "# Token Probabilities\n",
    "prob_token_spam = np.loadtxt(TOKEN_SPAM_PROB_FILE, delimiter=' ')\n",
    "prob_token_ham = np.loadtxt(TOKEN_HAM_PROB_FILE, delimiter=' ')\n",
    "prob_all = np.loadtxt(TOKEN_ALL_PROB_FILE, delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d187d1d1-64e3-4dbe-9160-d3bb492b5c4d",
   "metadata": {},
   "source": [
    "## Set the Prior\n",
    "\n",
    "$$P(Spam \\, | \\, X) = \\frac{P(X \\, | \\, Spam) \\, P(Spam)} {P(X)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f13abf4-5f9a-4b2b-a19d-170553342c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4722.14830944, -1305.58276457,  -309.50407213, ...,\n",
       "        -286.45007326,  -186.3597443 , -3254.94876172])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_log_spam = x_test.dot(np.log(prob_token_spam)) + np.log(PROB_SPAM)\n",
    "joint_log_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388dab12-a228-4a5a-87f2-e6d78bf34ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5523.48751036, -1407.80825526,  -364.67866321, ...,\n",
       "        -259.63517403,  -157.12276535, -3123.74039585])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_log_ham = x_test.dot(np.log(prob_token_ham)) + np.log(1 - PROB_SPAM)\n",
    "joint_log_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9995ed5c-25d9-462f-8204-22bb260a294c",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "### Checking for the higher joint probability\n",
    "\n",
    "$$P(Spam \\, | \\, X) \\, > \\, P(Ham \\, | \\, X)$$\n",
    "<center>**OR**</center>\n",
    "<br>\n",
    "$$P(Spam \\, | \\, X) \\, < \\, P(Ham \\, | \\, X)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15082619-5d26-4754-a941-53162dd380a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = joint_log_spam > joint_log_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7682f1-f599-4a3a-ae0e-e19f40dcf01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8e8dc-40f1-438a-8ad0-2ddcb6454713",
   "metadata": {},
   "source": [
    "# Metrics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b3a64d-674c-4282-bfd5-fcc5a714573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs classified correctly 1638\n",
      "Docs classified incorrectly 68\n"
     ]
    }
   ],
   "source": [
    "correct_pred = (y_test == prediction).sum()\n",
    "print('Docs classified correctly', correct_pred)\n",
    "wrong_pred = x_test.shape[0] - correct_pred\n",
    "print('Docs classified incorrectly', wrong_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5928340-e79d-4d5c-a4e1-071d1dea0fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9601406799531067"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "correct_pred/len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873d596a-c52a-441f-85fb-63045c0e7dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 96.01%\n",
      "Fraction classified incorrectly is 3.99%\n"
     ]
    }
   ],
   "source": [
    "fraction_wrong = wrong_pred / len(x_test)\n",
    "print(f'Accuracy of the model is {round(100*(1-fraction_wrong), 2)}%')\n",
    "print(f'Fraction classified incorrectly is {round(100*fraction_wrong, 2)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
